***************************************** Interview Questions Machine Learning*****************************

What’s the trade-off between bias and variance? or What do you understand by Bias Variance trade off?
	- Bias is error due to erroneous or overly simplistic assumptions in the learning algorithm you’re using.
	- This can lead to the model underfitting your data, making it hard for it to have high predictive accuracy and for you to generalize your knowledge from the training set to the test set.
	- In other Words, Bias error is useful to quantify how much on an average are the predicted values different from the actual value. 
	- A high bias error means we have a under-performing model which keeps on missing important trends.
	
	- Variance is error due to too much complexity in the learning algorithm you’re using.
	- This leads to the algorithm being highly sensitive to high degrees of variation in your training data, which can lead your model to overfit the data.
	- You’ll be carrying too much noise from your training data for your model to be very useful for your test data.
	- In Other Words, Variance on the other side quantifies how are the prediction made on same observation different from each other. 
	- A high variance model will over-fit on your training population and perform badly on any observation beyond training.
	
	- The bias-variance decomposition essentially decomposes the learning error from any algorithm by adding the bias, the variance and a bit of irreducible error due to noise in the underlying dataset.
	- Essentially, if you make the model more complex and add more variables, you’ll lose bias but gain some variance.
	- in order to get the optimally reduced amount of error, you’ll have to tradeoff bias and variance. You don’t want either high bias or high variance in your model.
	
	Proper Definition:
	- The error emerging from any model can be broken down into three components mathematically.
		BiasVaianceTradeOff.png
		
What is the difference between supervised and unsupervised machine learning?
	- Suprevised Learning:
		- it requires training labeled data.
		- Ex: in order to do classification (a supervised learning task), you’ll need to first label the data you’ll use to train the model to classify data into your labeled groups.
		- in simple words, if you are training your machine learning task for every input with corresponding target, it is called supervised learning, 
		which will be able to provide target for any new input after sufficient training.
		- Your learning algorithm seeks a function from inputs to the respective targets. 
		- If the targets are expressed in some classes, it is called classification problem. 
		- Alternatively, if the target space is continuous, it is called regression problem.
		
		
	- Unsupervised learning:
		- in contrast, does not require labeling data explicitly.
		- in Words, if you are training your machine learning task only with a set of inputs, it is called unsupervised learning, which will be able to find the structure or relationships between different inputs. 
		- clustering is the most important unsupervised learning Algorithm, which will create different cluster of inputs and will be able to put any new input in appropriate cluster.
		- Few Unsupervised learning algorithms are:
			- Anomaly detection
			- Hebbian Learning
			-  Latent variable models such as (Expectation–maximization algorithm,  Method of moments and etc...)
			
How is KNN different from k-means clustering?
	- K-Nearest Neighbors is a supervised classification algorithm
	- in order for K-Nearest Neighbors to work, you need labeled data you want to classify an unlabeled point into (thus the nearest neighbor part). 
	- KNN use the Euclidean distance and a value of k neighbors.
	
	- K-means clustering is an unsupervised clustering algorithm. 
	- K-means clustering requires only a set of unlabeled points and a threshold: the algorithm will take unlabeled points and gradually learn how to cluster them into groups by computing the mean of the distance between different points.
	- K-means belongs to the family of moving centroid algorithms
	
	Note: The critical difference here is that KNN needs labeled points and is thus supervised learning, while k-means doesn’t — and is thus unsupervised learning.
	
Explain how a ROC curve works. (Receiver operating characteristic)
	- The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds.
	- It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).
	- The true-positive rate is also known as sensitivity, recall or probability of detection in machine learning. 
	- The false-positive rate is also known as the fall-out or probability of false alarm and can be calculated as (1 − specificity).
	
Define precision and recall.
	- Recall is also known as the true positive rate: the amount of positives your model claims compared to the actual number of positives there are throughout the data. 
	- Precision is also known as the positive predictive value, and it is a measure of the amount of accurate positives your model claims compared to the number of positives it actually claims.
	- Suppose a computer program for recognizing dogs in photographs identifies 8 dogs in a picture containing 12 dogs and some cats. 
	- Of the 8 dogs identified, 5 actually are dogs (true positives), while the rest are cats (false positives).
	- The program's precision is 5/8 while its recall is 5/12.
	
What is Bayes’ Theorem? How is it useful in a machine learning context?
	- 
	
Why is “Naive” Bayes naive?
	- 
	
Explain the difference between L1 and L2 regularization.
	- L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting.
	- L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior.

What’s the difference between Type I and Type II error?
	- Type I error is a false positive, while Type II error is a false negative. 
	- Type I error means claiming something has happened when it hasn’t.
	- Type II error means that you claim nothing is happening when in fact something is.
	- In statistical hypothesis testing, a type I error is the rejection of a true null hypothesis (also known as a "false positive" finding),while a type II error is retaining a false null hypothesis (also known as a "false negative" finding)
	- More simply stated, a type I error is to falsely infer the existence of something that is not there, while a type II error is to falsely infer the absence of something that is.
	Note: In statistics, a null hypothesis is a statement that one seeks to nullify with evidence to the contrary.
	
What’s a Fourier transform?
	- 
	
What’s the difference between probability and likelihood?
	- 